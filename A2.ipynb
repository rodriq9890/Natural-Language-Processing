{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DS-UA 301 Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome back! In this notebook, we will explore and practice several foundational concepts and techniques in Natural Language Processing, specifically in the \"operate\" stage: \n",
    "+ Transforming documents into numbers\n",
    "+ Characterising documents\n",
    "+ Comparing documents \n",
    "+ Sentiment analysis\n",
    "\n",
    "We'll also *continue to* think about approaching our NLP work from a hypothesis-driven approach. I know you're probably sick of this, but I cannot overstate how important and useful it is to be super comfortable with thinking like this for all things job, discovery, and satisfaction-related (I think my claims are getting bolder as we go, but I stand by them!).\n",
    "\n",
    "Some tips (mostly the same as before, but good reminders): \n",
    "+ As with Assignment 1, you may use any data you like (built-in NLTK or something else!) as long as you are able to complete all the prompts below.\n",
    "+ As with Assignment 1, you're welcome to use a subset or the full dataset you plan to use for the project. No need to do the same thing twice. If you're still working on collecting your data, I suggest working with a \"toy\" mini-set (again, as long as it's big enough to complete the prompts).\n",
    "+ As before, while we will be grading you for correctness and completeness; i.e., you must correctly complete the specific tasks we ask of you, there is rarely a single \"right answer\" when it comes to *which* strategy to use. We care more that you thoughtfully and transparently explain your reasoning, rather than worrying whether you're \"right\".\n",
    "+ As before, 2-3 sentences (at most!) for the non-code questions should generally be enough. No need for essays!\n",
    "\n",
    "Finally, each question is worth 1 point, for 60 points total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Any pre-processing needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) We are going to begin this assignment from text that has already been pre-processed. You may thus use your text and/or program from Assignment 1 to pre-process your text here (no need to comment or explain anything, as you already did that). If you're using brand new text, you might need to do a bit more work, but a little extra practice won't work.\n",
    "\n",
    "Complete any pre-processing you need to do here, whether it's copying over your work from Assignment 1 or borrowing some of it as you apply it to a new text. \n",
    "\n",
    "*(Recap: what counts as pre-processing? Everything you did in Assignment 1!)*\n",
    "\n",
    "\n",
    "http://www.thegrammarlab.com/?nor-portfolio=corpus-of-presidential-speeches-cops-and-a-clintontrump-corpus\n",
    "\n",
    "^^^^\n",
    "\n",
    "Where I got the data from!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy_readability import Readability\n",
    "statess = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"District \", \"of Columbia\", \n",
    "               \"Delaware\", \"Florida\", \"Georgia\", \"Guam\", \"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Massachusetts\", \"Maryland\", \n",
    "               \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \"Mississippi\", \"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \n",
    "               \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Puerto Rico\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Virginia\", \n",
    "               \"Virgin Islands\", \"Vermont\", \"Washington\", \"Wisconsin\", \"West Virginia\", \"Wyoming\"]\n",
    "states = [word.lower() for word in statess]\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "clinton = open(\"clinton.txt\", \"r\").read().lower()\n",
    "trump = open(\"trump.txt\", \"r\").read().lower()\n",
    "clinton_raw = nltk.word_tokenize(clinton)\n",
    "trump_raw = nltk.word_tokenize(trump)\n",
    "removable_words = ['applause', \"'s\" , \"'re\", '--', \"n't\", 'title=', \"''\", \"'ve\", '...', 'delivers', 'remarks', \"\\\\users\\\\rodrigo\", \"gaming\", \"pc\\\\dropbox\\\\nlp\", \"corpus\\\\clinton-trump\", \"gaming\", \n",
    "                   '``', 'c', '\\\\users\\\\rodrigo', 'rl\\\\homework', '2\\\\clinton-trump', 'presidential', 'audience']\n",
    "clinton_tokens_stopwords = [elem for elem in clinton_raw if elem not in string.punctuation and elem not in removable_words]\n",
    "trump_tokens_stopwords  = [elem for elem in trump_raw if elem not in string.punctuation and elem not in removable_words]\n",
    "clinton_tokens = [elem for elem in clinton_raw if elem not in string.punctuation and elem not in stop_words and elem not in removable_words]\n",
    "trump_tokens  = [elem for elem in trump_raw if elem not in string.punctuation and elem not in stop_words and elem not in removable_words]\n",
    "proper_nouns = ['trump', 'donald', 'hillary', 'clinton', 'america']\n",
    "for word in range(len(clinton_tokens)):\n",
    "    if clinton_tokens[word] in proper_nouns or clinton_tokens[word] in states:\n",
    "        clinton_tokens[word] = clinton_tokens[word].capitalize()\n",
    "for word in range(len(trump_tokens)):\n",
    "    if trump_tokens[word] in proper_nouns or trump_tokens[word] in states:\n",
    "        trump_tokens[word] = trump_tokens[word].capitalize()\n",
    "clinton_postag = nltk.pos_tag(clinton_tokens)\n",
    "trump_postag = nltk.pos_tag(trump_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transforming documents into numbers\n",
    "\n",
    "We're going to need to turn our documents into numbers in order to proceed. We'll take care of that in this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) First, to make sure we're clear on what we're doing here: What is the Bag of Words (BOW) assumption, and why do we use it? What's so useful about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOW is a way to simplify a text to be able to be used in modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) What is at least one treadeoff, or shortcoming, when it comes to working under the BOW assumption?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is it simplifies perhaps too much, and several words could appear twice in the bag. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) It's time for our simplest expression of text as numeric data: the Document-Term Matrix (DTM). Convert your corpus into a DTM based simply on word counts. You may or may not have stop words and/or be working with stems/lemmas depending on your decisions you made in Question 1.\n",
    "\n",
    "*(Note: you can always go back and adjust your preprocessing decisions as you work through Assignment 2, just make sure to turn in the final product. There's no need to re-explain your pre-processing decisions in this Assignment, even if you tweak it as you go, as we got plenty of that last time and there's more to come in the project.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_count = Counter()\n",
    "c_count = Counter()\n",
    "c_count.update(word for word in clinton_tokens)\n",
    "t_count.update(word for word in trump_tokens)\n",
    "clinton_count = dict(c_count)\n",
    "trump_count = dict(t_count)\n",
    "dtm1 = pd.DataFrame(trump_count, index=[0]) \n",
    "dtm2 = pd.DataFrame(clinton_count, index=[1]) \n",
    "dtm = dtm1.merge(dtm2, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Donald</th>\n",
       "      <th>Trump</th>\n",
       "      <th>republican</th>\n",
       "      <th>candidate</th>\n",
       "      <th>volunteers</th>\n",
       "      <th>national</th>\n",
       "      <th>convention</th>\n",
       "      <th>date</th>\n",
       "      <th>2016-07-22</th>\n",
       "      <th>pence</th>\n",
       "      <th>...</th>\n",
       "      <th>worship</th>\n",
       "      <th>achieving</th>\n",
       "      <th>holton</th>\n",
       "      <th>graceful</th>\n",
       "      <th>crisscrossed</th>\n",
       "      <th>four-month-old</th>\n",
       "      <th>setbacks</th>\n",
       "      <th>deserving</th>\n",
       "      <th>seasons</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>385.0</td>\n",
       "      <td>2479.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>308.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>693.0</td>\n",
       "      <td>2926.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284903.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 12488 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Donald   Trump  republican  candidate  volunteers  national  \\\n",
       "Trump     385.0  2479.0       176.0      132.0         5.0     159.0   \n",
       "Clinton   308.0   447.0        50.0       58.0         4.0      87.0   \n",
       "Total     693.0  2926.0       226.0      190.0         9.0     246.0   \n",
       "\n",
       "         convention   date  2016-07-22  pence  ...  worship  achieving  \\\n",
       "Trump          38.0   99.0         1.0   81.0  ...      0.0        0.0   \n",
       "Clinton        55.0   36.0         0.0    1.0  ...      1.0        1.0   \n",
       "Total          93.0  135.0         1.0   82.0  ...      1.0        1.0   \n",
       "\n",
       "         holton  graceful  crisscrossed  four-month-old  setbacks  deserving  \\\n",
       "Trump       0.0       0.0           0.0             0.0       0.0        0.0   \n",
       "Clinton     1.0       1.0           1.0             1.0       2.0        1.0   \n",
       "Total       1.0       1.0           1.0             1.0       2.0        1.0   \n",
       "\n",
       "         seasons     Total  \n",
       "Trump        0.0  223084.0  \n",
       "Clinton      1.0   61819.0  \n",
       "Total        1.0  284903.0  \n",
       "\n",
       "[3 rows x 12488 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = dtm.rename(index={0: 'Trump', 1:'Clinton'}).fillna(0)\n",
    "dtm.loc['Total']= dtm.sum()\n",
    "dtm['Total'] = dtm.sum(axis=1)\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) DTMs are typically sparse matrices. What do we mean by \"sparse matrix\", and is yours one? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really, there are only two indices and I don't think there are many words that either candidate would use that the other wouldn't. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) We also discussed that DTMs require lossy compression. What is meant by \"lossy compression\" and why might it matter for some analyses? Does it matter for yours?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lossy compression means losing some of the original information on a dataset to allow for smaller sizes. I don't know if it matters much in this case to be honest since I counted every single word by code and not by any other method from NLTK or any other module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) DTMs do not have to be limited top single words; we can use n-grams as well. Create a DTM based on an n-gram with an *n* size you think is appropriate for your text. (If you think unigrams are most appropriate, indulge me and pick a runner-up :)!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs_trump = nltk.trigrams(trump_tokens)\n",
    "fdist_trump = nltk.FreqDist(bgs_trump)\n",
    "bgs_clinton = nltk.trigrams(clinton_tokens)\n",
    "fdist_clinton = nltk.FreqDist(bgs_clinton)\n",
    "df1_ngram = pd.DataFrame(dict(fdist_trump), index=[0]) \n",
    "df2_ngram = pd.DataFrame(dict(fdist_clinton), index=[0]) \n",
    "dtm_ngram = df1_ngram.merge(df2_ngram, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>make</th>\n",
       "      <th>Trump</th>\n",
       "      <th>going</th>\n",
       "      <th>Hillary</th>\n",
       "      <th>bring</th>\n",
       "      <th>usa</th>\n",
       "      <th>wall</th>\n",
       "      <th>going</th>\n",
       "      <th>Donald</th>\n",
       "      <th>...</th>\n",
       "      <th>want</th>\n",
       "      <th>protect</th>\n",
       "      <th>country</th>\n",
       "      <th>potential</th>\n",
       "      <th>adversaries</th>\n",
       "      <th>grow</th>\n",
       "      <th>missile</th>\n",
       "      <th>programs</th>\n",
       "      <th>u.s.</th>\n",
       "      <th>goes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>America</th>\n",
       "      <th>Trump</th>\n",
       "      <th>take</th>\n",
       "      <th>Clinton</th>\n",
       "      <th>back</th>\n",
       "      <th>usa</th>\n",
       "      <th>build</th>\n",
       "      <th>make</th>\n",
       "      <th>Trump</th>\n",
       "      <th>...</th>\n",
       "      <th>protect</th>\n",
       "      <th>country</th>\n",
       "      <th>potential</th>\n",
       "      <th>adversaries</th>\n",
       "      <th>grow</th>\n",
       "      <th>missile</th>\n",
       "      <th>programs</th>\n",
       "      <th>u.s.</th>\n",
       "      <th>military</th>\n",
       "      <th>hell</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>great</th>\n",
       "      <th>Trump</th>\n",
       "      <th>care</th>\n",
       "      <th>wants</th>\n",
       "      <th>jobs</th>\n",
       "      <th>usa</th>\n",
       "      <th>wall</th>\n",
       "      <th>America</th>\n",
       "      <th>republican</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>potential</th>\n",
       "      <th>adversaries</th>\n",
       "      <th>grow</th>\n",
       "      <th>missile</th>\n",
       "      <th>programs</th>\n",
       "      <th>u.s.</th>\n",
       "      <th>military</th>\n",
       "      <th>facilities</th>\n",
       "      <th>laughter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>223082.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>61817.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>284899.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 234089 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Total    make  Trump going Hillary bring   usa  wall   going  \\\n",
       "                  America  Trump  take Clinton  back   usa build    make   \n",
       "                    great  Trump  care   wants  jobs   usa  wall America   \n",
       "Trump    223082.0   140.0  143.0  98.0    95.0  93.0  83.0  83.0    79.0   \n",
       "Clinton   61817.0     6.0    0.0   0.0     0.0   0.0   1.0   0.0     3.0   \n",
       "Total    284899.0   146.0  143.0  98.0    95.0  93.0  84.0  83.0    82.0   \n",
       "\n",
       "            Donald  ...    want   protect     country   potential adversaries  \\\n",
       "             Trump  ... protect   country   potential adversaries        grow   \n",
       "        republican  ... country potential adversaries        grow     missile   \n",
       "Trump         80.0  ...     1.0       1.0         1.0         1.0         1.0   \n",
       "Clinton        0.0  ...     0.0       0.0         0.0         0.0         0.0   \n",
       "Total         80.0  ...     1.0       1.0         1.0         1.0         1.0   \n",
       "\n",
       "            grow  missile programs       u.s.     goes  \n",
       "         missile programs     u.s.   military     hell  \n",
       "        programs     u.s. military facilities laughter  \n",
       "Trump        1.0      1.0      1.0        1.0      1.0  \n",
       "Clinton      0.0      0.0      0.0        0.0      0.0  \n",
       "Total        1.0      1.0      1.0        1.0      1.0  \n",
       "\n",
       "[3 rows x 234089 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_ngram = dtm_ngram.rename(index={0: 'Trump', 1:'Clinton'}).fillna(0)\n",
    "dtm_ngram.loc['Total']= dtm_ngram.sum()\n",
    "dtm_ngram['Total'] = dtm_ngram.sum(axis=1)\n",
    "dtm_ngram.T.sort_values(by='Total', ascending=False).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Why did you choose that particular *n* value of n-gram? Did it improve anything in your analysis? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigrams are good enough to catch any of trumps catch phrases, and many of Hilary's, but to be honest, her phrases aren't as memorable as Trump's. We can see this above where make America great is the top with very few aid from any of Hillary's uses of the trigram, in fact, most trigrams on top are Trump's own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(h) Usually when we work with n-grams we retain a few that might matter for our analysis. If there are any such n-grams, please add them to your unigram-based DTM now as unique terms (you can do so however you like). Why did you retain the n-grams that you did? If you are not retaining any n-grams, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course I'm keeping some of these, I'm keeping the ones most unique to each candidate, to do that, I'll sort and find their most common trigrams excluding their names three times and usa*3\n",
    "\n",
    "On second thought, Hillary doesn't even have many trigrams on her dtm of trigrams, most are trumps, look below for evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Hillary</th>\n",
       "      <th>Clinton</th>\n",
       "      <th>president</th>\n",
       "      <th>Hillary</th>\n",
       "      <th>world</th>\n",
       "      <th>every</th>\n",
       "      <th>candidate</th>\n",
       "      <th>democratic</th>\n",
       "      <th>...</th>\n",
       "      <th>say</th>\n",
       "      <th>help</th>\n",
       "      <th>everybody</th>\n",
       "      <th>help</th>\n",
       "      <th>na</th>\n",
       "      <th>something</th>\n",
       "      <th>great</th>\n",
       "      <th>America</th>\n",
       "      <th>thank</th>\n",
       "      <th>goes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Hillary</th>\n",
       "      <th>democratic</th>\n",
       "      <th>united</th>\n",
       "      <th>Clinton</th>\n",
       "      <th>war</th>\n",
       "      <th>single</th>\n",
       "      <th>campaign</th>\n",
       "      <th>candidate</th>\n",
       "      <th>...</th>\n",
       "      <th>help</th>\n",
       "      <th>everybody</th>\n",
       "      <th>help</th>\n",
       "      <th>gon</th>\n",
       "      <th>something</th>\n",
       "      <th>going</th>\n",
       "      <th>know</th>\n",
       "      <th>great</th>\n",
       "      <th>everybody</th>\n",
       "      <th>hell</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Hillary</th>\n",
       "      <th>Clinton</th>\n",
       "      <th>candidate</th>\n",
       "      <th>states</th>\n",
       "      <th>democratic</th>\n",
       "      <th>ii</th>\n",
       "      <th>day</th>\n",
       "      <th>event</th>\n",
       "      <th>campaign</th>\n",
       "      <th>...</th>\n",
       "      <th>everybody</th>\n",
       "      <th>help</th>\n",
       "      <th>gon</th>\n",
       "      <th>na</th>\n",
       "      <th>going</th>\n",
       "      <th>make</th>\n",
       "      <th>make</th>\n",
       "      <th>want</th>\n",
       "      <th>really</th>\n",
       "      <th>laughter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>223082.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>61817.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>284899.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 234089 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Total Hillary            Clinton president    Hillary world  \\\n",
       "                  Hillary         democratic    united    Clinton   war   \n",
       "                  Hillary Clinton  candidate    states democratic    ii   \n",
       "Trump    223082.0     0.0     1.0        0.0      41.0        1.0   5.0   \n",
       "Clinton   61817.0    37.0    29.0       29.0      25.0       23.0  22.0   \n",
       "Total    284899.0    37.0    30.0       29.0      66.0       24.0  27.0   \n",
       "\n",
       "         every candidate democratic  ...       say      help everybody help  \\\n",
       "        single  campaign  candidate  ...      help everybody      help  gon   \n",
       "           day     event   campaign  ... everybody      help       gon   na   \n",
       "Trump      7.0      59.0        0.0  ...       1.0       1.0       1.0  3.0   \n",
       "Clinton   21.0      20.0       20.0  ...       0.0       0.0       0.0  0.0   \n",
       "Total     28.0      79.0       20.0  ...       1.0       1.0       1.0  3.0   \n",
       "\n",
       "               na something great America     thank     goes  \n",
       "        something     going  know   great everybody     hell  \n",
       "            going      make  make    want    really laughter  \n",
       "Trump         1.0       1.0   1.0     2.0       2.0      1.0  \n",
       "Clinton       0.0       0.0   0.0     0.0       0.0      0.0  \n",
       "Total         1.0       1.0   1.0     2.0       2.0      1.0  \n",
       "\n",
       "[3 rows x 234089 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_ngram.T.sort_values(by='Clinton', ascending=False).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trump's are more interesting and telling of his character (confrontational and sentimental) I'll keep 2-5 because these are great for telling trump's sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:618: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 3 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "trump_ngrams = dtm_ngram.T.sort_values(by='Trump', ascending=False).iloc[2:6].T\n",
    "dtm = dtm.join(trump_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've merged these four trigrams into the dtm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Donald</th>\n",
       "      <th>Trump</th>\n",
       "      <th>republican</th>\n",
       "      <th>candidate</th>\n",
       "      <th>volunteers</th>\n",
       "      <th>national</th>\n",
       "      <th>convention</th>\n",
       "      <th>date</th>\n",
       "      <th>2016-07-22</th>\n",
       "      <th>pence</th>\n",
       "      <th>...</th>\n",
       "      <th>crisscrossed</th>\n",
       "      <th>four-month-old</th>\n",
       "      <th>setbacks</th>\n",
       "      <th>deserving</th>\n",
       "      <th>seasons</th>\n",
       "      <th>Total</th>\n",
       "      <th>(make, America, great)</th>\n",
       "      <th>(going, take, care)</th>\n",
       "      <th>(Hillary, Clinton, wants)</th>\n",
       "      <th>(bring, back, jobs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>385.0</td>\n",
       "      <td>2479.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223084.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>308.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61819.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>693.0</td>\n",
       "      <td>2926.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284903.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 12492 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Donald   Trump  republican  candidate  volunteers  national  \\\n",
       "Trump     385.0  2479.0       176.0      132.0         5.0     159.0   \n",
       "Clinton   308.0   447.0        50.0       58.0         4.0      87.0   \n",
       "Total     693.0  2926.0       226.0      190.0         9.0     246.0   \n",
       "\n",
       "         convention   date  2016-07-22  pence  ...  crisscrossed  \\\n",
       "Trump          38.0   99.0         1.0   81.0  ...           0.0   \n",
       "Clinton        55.0   36.0         0.0    1.0  ...           1.0   \n",
       "Total          93.0  135.0         1.0   82.0  ...           1.0   \n",
       "\n",
       "         four-month-old  setbacks  deserving  seasons     Total  \\\n",
       "Trump               0.0       0.0        0.0      0.0  223084.0   \n",
       "Clinton             1.0       2.0        1.0      1.0   61819.0   \n",
       "Total               1.0       2.0        1.0      1.0  284903.0   \n",
       "\n",
       "         (make, America, great)  (going, take, care)  \\\n",
       "Trump                     140.0                 98.0   \n",
       "Clinton                     6.0                  0.0   \n",
       "Total                     146.0                 98.0   \n",
       "\n",
       "         (Hillary, Clinton, wants)  (bring, back, jobs)  \n",
       "Trump                         95.0                 93.0  \n",
       "Clinton                        0.0                  0.0  \n",
       "Total                         95.0                 93.0  \n",
       "\n",
       "[3 rows x 12492 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Finally, we can also transform documents into numbers using strategies other than simple word counts. Create a DTM for your corpus using TF-IDF scores rather than word counts.\n",
    "\n",
    "I'm implementing TF-IDF from this site: https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trump</th>\n",
       "      <th>Clinton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>obamacare</th>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borders</th>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nafta</th>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hannity</th>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dishonest</th>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appear</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matt</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dye</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrassing</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Trump   Clinton\n",
       "obamacare     0.000873  0.000000\n",
       "borders       0.000758  0.000000\n",
       "nafta         0.000690  0.000000\n",
       "hannity       0.000628  0.000000\n",
       "dishonest     0.000513  0.000000\n",
       "appear        0.000000  0.000000\n",
       "page          0.000000  0.000000\n",
       "matt          0.000000  0.000000\n",
       "dye           0.000000  0.000034\n",
       "embarrassing  0.000000  0.000022"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueWords = set(trump_tokens).union(set(clinton_tokens))\n",
    "numOfWords_trump = dict.fromkeys(uniqueWords, 0)\n",
    "for word in trump_tokens:\n",
    "    numOfWords_trump[word] += 1\n",
    "numOfWords_clinton= dict.fromkeys(uniqueWords, 0)\n",
    "for word in clinton_tokens:\n",
    "    numOfWords_clinton[word] += 1\n",
    "\n",
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict\n",
    "tf_trump = computeTF(numOfWords_trump, trump_tokens)\n",
    "tf_clinton = computeTF(numOfWords_clinton, clinton_tokens)\n",
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict\n",
    "idfs = computeIDF([numOfWords_trump, numOfWords_clinton])\n",
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf\n",
    "tfidf_trump = computeTFIDF(tf_trump, idfs)\n",
    "tfidf_clinton = computeTFIDF(tf_clinton, idfs)\n",
    "tfidf = pd.DataFrame([tfidf_trump, tfidf_clinton]).rename(index={0: 'Trump', 1:'Clinton'})\n",
    "tfidf_trump_sort = tfidf.T.sort_values(by='Trump', ascending=False)\n",
    "tfidf_clinton_sort = tfidf.T.sort_values(by='Clinton', ascending=False)\n",
    "tfidf_trump_sort.head().append(tfidf_trump_sort.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trump</th>\n",
       "      <th>Clinton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cheers</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fairer</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insults</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maggie</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hillaryclinton.com</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interest</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beloved</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amendment.</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impressions</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scientific</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Trump   Clinton\n",
       "cheers              0.000000  0.000863\n",
       "fairer              0.000000  0.000370\n",
       "insults             0.000000  0.000303\n",
       "maggie              0.000000  0.000292\n",
       "hillaryclinton.com  0.000000  0.000269\n",
       "interest            0.000000  0.000000\n",
       "beloved             0.000000  0.000000\n",
       "amendment.          0.000003  0.000000\n",
       "impressions         0.000006  0.000000\n",
       "scientific          0.000000  0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_clinton_sort.head().append(tfidf_clinton_sort.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(j) To make sure we're all clear on what's going on with TF-IDF, what do words in your corpus with high TF-IDF scores represent (i.e., what do we learn about these words given this high score)? What about the words with low TF-IDF scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high tf-idf score means that word is particularily important to that document. Low scores means that word isn't particularily important. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(k) It may be hard to say until you've done later analyses, but how useful do you think the word count DTM vs. the TF-IDF DTM will be for your analysis? Is one more \"representative\" of your text than the other? On what are you basing this conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not sure that the tfidf for Clinton worked that well since cheers is the most \"significant\" word, whereas for trump I think it worked perfectly. Trump attacked obamacare, borders, nafta, and called anyone dishonest while supporting hannity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Characterising documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) It's time to start doing some descriptive analyses of our corpus. First, let's evaluate whether our corpus is the first text in the history of the world to violate Zipf's law. Generate a term frequency plot below. (If you removed stop words previously, you may need to put them temporarily back in.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "t_count_stopwords = Counter()\n",
    "c_count_stopwords = Counter()\n",
    "c_count_stopwords.update(word for word in clinton_tokens_stopwords)\n",
    "t_count_stopwords.update(word for word in trump_tokens_stopwords)\n",
    "clinton_count_stopwords = dict(c_count_stopwords)\n",
    "trump_count_stopwords = dict(t_count_stopwords)\n",
    "dtm1_stopwords = pd.DataFrame(trump_count_stopwords, index=[0]) \n",
    "dtm2_stopwords = pd.DataFrame(clinton_count_stopwords, index=[1]) \n",
    "dtm_stopwords = dtm1_stopwords.merge(dtm2_stopwords, how='outer')\n",
    "dtm_stopwords.loc['Total'] = dtm_stopwords.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "the     21447.0\n",
       "and     20521.0\n",
       "to      19351.0\n",
       "we      13683.0\n",
       "i       13411.0\n",
       "you     11670.0\n",
       "of      11469.0\n",
       "a       11297.0\n",
       "it       9831.0\n",
       "that     9663.0\n",
       "Name: Total, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_stopwords.T.sort_values(by='Total', ascending=False).reset_index()['Total'].plot.line()\n",
    "plt.title('Frequency of words in corpus with Stop Words (Log Scale)')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "dtm_stopwords.T.sort_values(by='Total', ascending=False)['Total'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) How did your corpus do? Have we stumbled upon a new discovery?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same old story as always."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) BTW: Which explanation for Zipf's law in the context of language do you find most compelling, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think these words have become so ubiquitous to conveying information that there aren't really alternatives to these words. Like, how would you replace the, or, you, I.\n",
    "\n",
    "Maybe there are some words in old english used as alternative for these words, but they're not common nowadays and if we'd like to convey words to the average person, we'll use average words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) We're now going to choose some key words for your corpus. These are words that \"characterise\" or are especially informative of your corpus. You can use either frequently appearing words, words with high TF-IDF scores, or something else, such as using some other rule (e.g., \"proper nouns\") or simply choosing the words you're most interested in. List five key words below and why you've chosen them. If you don't have as many as five, explain why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to choose emails, obamacare, wall, and border\n",
    "\n",
    "Hillary doesn't have any particularily good words in her tokens, trump has many,\n",
    "\n",
    "I have also just found out how small the hillary corpus is compared to trump's but it's from a website that already had them all in there. Perhaps trump did more speeches than hillary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) We're going to inspect concordance plots, or \"key word in context\" (KWIC) plots now. Before we do, generate one hypothesis you can test with a KWIC plot. For example, you could test whether two key words typically have different contexts around them, or whether one key word's contex has changed over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In trump's case, I expect jobs and mexico to share very similar contexts. As well as going.\n",
    "\n",
    "In hillary's case, I expect insults to be in very similar contexts to other groups of people or donald trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Testing time! Generate the relevant plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 377 matches:\n",
      "wheat right trade imbalance massive mexico unbelievably big trade imbalance ki\n",
      "traffic tough build wall easily way mexico going pay wall going pay wall got g\n",
      "ke country 'm going bring jobs back mexico booming booming friend builds plant\n",
      "good news country well country well mexico unbelievable plants 'm building mex\n",
      "ico unbelievable plants 'm building mexico never seen anything eighth wonder w\n",
      " job number one get jobs jobs going mexico going china going japan going place\n",
      "ee ford see companies leaving going mexico like nothing make product sell back\n",
      "ooked going jobs torn country going mexico china happening china isis military\n",
      " listen going fire everybody moving mexico another case booing know much effec\n",
      "undreds companies moving case going mexico many go mexico case going mexico an\n",
      "es moving case going mexico many go mexico case going mexico announce closing \n",
      "ng mexico many go mexico case going mexico announce closing going fire everybo\n",
      "ing going fire everybody going move mexico going make air conditioners going s\n",
      "reat leadership 'm angry leadership mexico japan vietnam new strong vietnam ch\n",
      "lant say listen really happy moving mexico think wonderful hot wonderful story\n",
      "rful hot wonderful story going move mexico every single time make air conditio\n",
      "ng understand leaving going Indiana mexico right yes well hope change mind wel\n",
      " go right ca really end ok end move mexico 'll sell goods 1400 people unemploy\n",
      " give quiz want quiz going pay wall mexico d. Trump mexico d. Trump 100 percen\n",
      "quiz going pay wall mexico d. Trump mexico d. Trump 100 percent 100 percent kn\n",
      "tly hold clowns back pundits saying mexico never going pay wall mexico know mu\n",
      " saying mexico never going pay wall mexico know much money make us year 'm inc\n",
      " bring back jobs gon na let jobs go mexico countries gon na renegotiate horrib\n",
      "gon na build wall gon na build wall mexico gon na pay wall reason politicians \n",
      "erstand going pay making much money mexico taking business friend mine builds \n",
      "\n",
      "\n",
      "Displaying 25 of 27 matches:\n",
      "ge mocks mimics reporter disability insults prisoners war like john mccain hero\n",
      "federal judge mexican heritage fair insults gold star family muslim american se\n",
      "l attacks name-calling revels think insults bullying get things done think appr\n",
      "rds teleprompter laughter still man insults gold star families demeans women mo\n",
      "mp ask 'm proud run campaign issues insults 'm going continue next 83 days thin\n",
      "xt certainly takes trying make year insults insinuations dropping neighbors hou\n",
      "paign running campaign based issues insults believe anyone asks vote tell going\n",
      "nerals claims armed forces disaster insults gold star family wrong offensive da\n",
      " together going run campaign issues insults going absolutely strong support uni\n",
      "nerals claims armed forces disaster insults gold star family offensive dangerou\n",
      "d tim kaine running campaign issues insults believe anybody asking vote importa\n",
      "g tim kaine running campaign issues insults Donald Trump different approach wan\n",
      " respecting avoid kind name-calling insults see much 'm excited campaign 'm eve\n",
      "sanders ran campaign campaign ideas insults campaigns bernie got together put h\n",
      "end someone like becoming president insults half population united states Ameri\n",
      "ing immigrants moves insult latinos insults african americans insults muslims i\n",
      "t latinos insults african americans insults muslims insults people disabilities\n",
      "s african americans insults muslims insults people disabilities insults pows in\n",
      "muslims insults people disabilities insults pows insults women inaudible time a\n",
      "ts people disabilities insults pows insults women inaudible time add people ins\n",
      "ans women mocks people disabilities insults african americans latinos demonizes\n",
      "ine run campaign based ideas issues insults cheers really take look stake elect\n",
      "sident demeans women mocks disabled insults african-americans latinos muslims b\n",
      "ca great race marked ugly suspicion insults attacks kinds immigrants muslims ma\n",
      "laughter great primary ideas issues insults 'm proud race senator sanders ran g\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.text import Text  \n",
    "trump_text = nltk.Text(trump_tokens)\n",
    "clinton_text = nltk.Text(clinton_tokens)\n",
    "\n",
    "def getConcordance(string, candidate):\n",
    "    if candidate.lower() == 'trump':\n",
    "        trump_text.concordance(string.lower())\n",
    "        print('\\n')\n",
    "    if candidate.lower() == 'clinton':\n",
    "        clinton_text.concordance(string.lower())\n",
    "        print('\\n')\n",
    "getConcordance('mexico', 'TrUmP')\n",
    "getConcordance('insults', 'clinton')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) How did your hypothesis do? As ever, no need to worry about statistical significance right now -- and this inspection in particular is pretty analog. But please comment on whether the differences you hypothesized were borne out, and how you reached that conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got them both right, Mexico is along the same contexts as going or moving jobs to.\n",
    "\n",
    "Insults is along the same contexts and people like the gold star faimily, african americans, muslims, disabled, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(h) We're going to do the same exercise for lexical dispersion plots. Again, they're pretty low-tech as NLP goes, but depending on your corpus could yield interesting insights. Generate one hypothesis about your corpus that you can test with a lexical dispersion plot(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expect trump to ramp up his use of wikileaks and emails and variations by the end of the campaign, as well as mention FBI more often\n",
    "\n",
    "I expect Hillary to use gold and star to line up almost perfectly, along with insult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Ok, generate your plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.draw.dispersion import dispersion_plot\n",
    "plt.figure(figsize=(12, 9))\n",
    "trump_words = ['benghazi', 'wikileaks', 'email', 'emails', 'fbi']\n",
    "dispersion_plot(trump_text, trump_words, ignore_case=True, title='Lexical Dispersion Plot')\n",
    "plt.figure(figsize=(12, 9))\n",
    "clinton_words = ['gold','star']\n",
    "dispersion_plot(clinton_text, clinton_words, ignore_case=True, title='Lexical Dispersion Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(j) How did your hypothesis do? Briefly explain your assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think they were both correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing documents: similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Now we're going to compare documents in your corpus. First, we'll examine similarity. Generate one hypothesis you can test regarding the likely similarity of documents in your corpus (between different types, over time, by different authors, etc.). You may test all documents or some subset -- whatever makes sense for your hypothesis and corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expect most of the corpus words to be shared with the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Evaluate the cosine similarity between the documents specified in your hypothesis above.\n",
    "\n",
    "https://www.geeksforgeeks.org/python-measure-similarity-between-two-sentences-using-cosine-similarity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity:  0.9996544073064795\n",
      "Angle:  1.5063726241857764\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from math import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos = cosine_similarity(dtm.iloc[:2], dtm.iloc[:2])\n",
    "print(\"similarity: \", cos[0][1]) \n",
    "print('Angle: ', math.degrees(math.acos(cos[0][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) How did your hypothesis hold up? Briefly explain your assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yea this is what I expected, most words are shared between the two candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Now we're going to test your hypothesis using a different distance metric (you can use any you like). Briefly describe which you chose and why (\"I learned Euclidean distance in another class\" is a fine answer here!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I learned something about eucledian distance in my linear algebra class but don't remember it much to be honest :/\n",
    "\n",
    "And I don't really know how to interpret this result to be honest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Test your hypothesis using the additional distance metric you selected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161522.4381997746"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "euclidean_distances(dtm.iloc[:2], dtm.iloc[:2])[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) How did your hypothesis hold up with this alternative distance metric? Briefly explain your assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not sure if this number is correct due to the fact that the Trump corpus is almost 4 times as big as the hillary one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Which distance metric do you think is more appropriate for your corpus, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know why but I feel that the cosine similarity is easier to interpret and use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(h) Did anything in this similarity analysis surprise you? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just how similar the words were in each corpus, I expected more differences but that wasn't the case, even given the vastly different corpus sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparing documents: diversity & complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) We're going to explore the linguistic diversity and complexity of your corpus. First, a few conceptual questions: what is meant by *lexical diversity*, and why is it so hard to measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lexical diversity is the variety of unique words in each corpus compared to the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) What are some reasons why we might want to measure the diversity of a document or corpus? (There are no wrong answers except variants on \"none\"!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways of expressing diversity, not only counting unique words per document (different POS, use of political lingo, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) What is meant by *linguistic complexity*, and why is it so hard to measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linguistic complexity is a measure of how readable or rich a text is in its tokens. It is hard to measure because, like diversity there are many ways of measuring it. We also did an example in class where for people whose native language is japanese, mandarin might be easier to learn that for native english speakers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) What are some reasons why we might want to measure the complexity of a document or corpus? (There are no wrong answers except variants on \"none\"!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to measure how different two documents speak on a similar subject, or whether one just elongates sentences to seem \"smarter\" than it really is. There are many reasons to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Generate a hypothesis about the lexical diversity in your corpus -- again, by some subset of documents, or over time, or anything you like. We aren't being too particular about the theoretical motivations behind your hypothesis -- just something you think is even vaguely (hopefully) interesting is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the mere fact that Trump's document is larger than Clinton's, I expect trump's to have more diversity, but Trump is also known to use very simple, child-like sentences in his speeches instead of large words.\n",
    "\n",
    "https://shravan-kuchkula.github.io/Lexical-Diversity/#lexical-diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Test your hypothesis using one measure of lexical diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)\n",
    "\n",
    "def percentage(count, total):\n",
    "    return 100 * count / total\n",
    "texts = [clinton_tokens, trump_tokens]\n",
    "\n",
    "lexicalDiversity = [lexical_diversity(text) for text in texts]\n",
    "tokens = [len(text) for text in texts]\n",
    "types = [len(set(text)) for text in texts]\n",
    "\n",
    "ld_ttr = pd.DataFrame({'tokens': tokens, 'types': types,\n",
    "                   'lexical_diversity': lexicalDiversity})\n",
    "ld_ttr = ld_ttr.sort_values(by='lexical_diversity', ascending=False).rename(index={0: 'Clinton', 1:'Trump'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>types</th>\n",
       "      <th>lexical_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>61819</td>\n",
       "      <td>6743</td>\n",
       "      <td>0.109076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>223084</td>\n",
       "      <td>10087</td>\n",
       "      <td>0.045216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tokens  types  lexical_diversity\n",
       "Clinton   61819   6743           0.109076\n",
       "Trump    223084  10087           0.045216"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ld_ttr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Test your hypothesis using another measure of lexical diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>types</th>\n",
       "      <th>lexical_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>248.63427</td>\n",
       "      <td>6743</td>\n",
       "      <td>27.120155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>472.31769</td>\n",
       "      <td>10087</td>\n",
       "      <td>21.356388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tokens  types  lexical_diversity\n",
       "Clinton  248.63427   6743          27.120155\n",
       "Trump    472.31769  10087          21.356388"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / sqrt(len(text))\n",
    "\n",
    "def percentage(count, total):\n",
    "    return 100 * count / sqrt(total)\n",
    "texts = [clinton_tokens, trump_tokens]\n",
    "lexicalDiversity = [lexical_diversity(text) for text in texts]\n",
    "tokens = [sqrt(len(text)) for text in texts]\n",
    "types = [len(set(text)) for text in texts]\n",
    "ld_r = pd.DataFrame({'tokens': tokens, 'types': types,\n",
    "                   'lexical_diversity': lexicalDiversity})\n",
    "ld_r = ld_r.sort_values(by='lexical_diversity', ascending=False).rename(index={0: 'Clinton', 1:'Trump'})\n",
    "ld_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(h) How did your hypothesis hold up in these two models? Which model of lexical diversity do you think is a better fit for your work, and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are correct! Clinton used more diverse words in her speehces even though they were 1/4 length of Trump's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) We'll do a similar, but shorter analysis for complexity. What's a hypothesis you can test? (Your answers can be brief, as a reminder!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trump's speeches are less complex that Hillary's by a substantial margin\n",
    "\n",
    "To use Spacy I had to cut trump's speeches into thirds and get stats on each third individually, then averaged these all out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(j) Test your hypothesis from above using one measure of complexity. (You won't have to use a second one this time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "clinton_spacydoc = nlp(clinton)\n",
    "trump_spacydoc1 = nlp(trump[:999999])\n",
    "trump_spacydoc2 = nlp(trump[1000000:1999999])\n",
    "trump_spacydoc3 = nlp(trump[2000000:2622073])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy_readability import Readability\n",
    "nlp.add_pipe(Readability())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinton Readability Statistics\n",
      "\n",
      "Flesch Kincaid Grade Level:  4.807858317246026\n",
      "Flesch Kincaid Reading Ease:   79.9887423661505\n",
      "Dale Chall:  7.4482788455837365\n",
      "Smog:  14.21603231612426\n",
      "Coleman Liau Index:  6.5396551549193696\n",
      "Automated Readability Index:  4.126606026937441\n",
      "Forcast 12.9\n",
      "\n",
      "Trump Readability Statistics\n",
      "\n",
      "Flesch Kincaid Grade Level:  3.676956292257813\n",
      "Flesch Kincaid Reading Ease:   84.09314950138184\n",
      "Dale Chall:  7.43812685357518\n",
      "Smog:  12.585993184840518\n",
      "Coleman Liau Index:  5.70772811670319\n",
      "Automated Readability Index:  2.925508068815391\n",
      "Forcast 11.833333333333334\n"
     ]
    }
   ],
   "source": [
    "print('Clinton Readability Statistics\\n')\n",
    "print('Flesch Kincaid Grade Level: ', clinton_spacydoc._.flesch_kincaid_grade_level)\n",
    "print('Flesch Kincaid Reading Ease:  ',clinton_spacydoc._.flesch_kincaid_reading_ease)\n",
    "print('Dale Chall: ', clinton_spacydoc._.dale_chall)\n",
    "print('Smog: ', clinton_spacydoc._.smog)\n",
    "print('Coleman Liau Index: ', clinton_spacydoc._.coleman_liau_index)\n",
    "print('Automated Readability Index: ', clinton_spacydoc._.automated_readability_index)\n",
    "print('Forcast', clinton_spacydoc._.forcast)\n",
    "\n",
    "trump_kincaid_gl = 0\n",
    "trump_kincaid_re = 0\n",
    "trump_dale_chall = 0\n",
    "trump_smog = 0\n",
    "trump_cl_index = 0\n",
    "trump_autori = 0\n",
    "trump_forcast = 0\n",
    "for trump in [trump_spacydoc1, trump_spacydoc2, trump_spacydoc3]:\n",
    "    trump_kincaid_gl += trump._.flesch_kincaid_grade_level\n",
    "    trump_kincaid_re += trump._.flesch_kincaid_reading_ease\n",
    "    trump_dale_chall += trump._.dale_chall\n",
    "    trump_smog += trump._.smog\n",
    "    trump_cl_index += trump._.coleman_liau_index\n",
    "    trump_autori += trump._.automated_readability_index\n",
    "    trump_forcast += trump._.forcast\n",
    "print('\\nTrump Readability Statistics\\n')\n",
    "print('Flesch Kincaid Grade Level: ', trump_kincaid_gl/3)\n",
    "print('Flesch Kincaid Reading Ease:  ',trump_kincaid_re/3)\n",
    "print('Dale Chall: ', trump_dale_chall/3)\n",
    "print('Smog: ', trump_smog/3)\n",
    "print('Coleman Liau Index: ', trump_cl_index/3)\n",
    "print('Automated Readability Index: ', trump_autori/3)\n",
    "print('Forcast', trump_forcast/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(k) How did your hypothesis do? Briefly explain your assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even though Trump's speeches were almost 4 numerous as large as Hillary's (~600k words vs 2.3m words), Hillary's readability stats are larger. \n",
    "\n",
    "Flesch Kincaid level is a whole grade above Trump's for hillary. \n",
    "\n",
    "Reading ease is lower for Hillary (More complicated text)\n",
    "\n",
    "Dale Chall is about the same.\n",
    "\n",
    "Coleman index for Hillary is a whole point above Trump's\n",
    "\n",
    "Smog is higher for Hillary by almost two levels.\n",
    "\n",
    "Automated Readability is higher for Hillary by a substantial margin. \n",
    "\n",
    "Forcast was also larger for Hillary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(l) Did you learn anything surprising about your corpus or documents during the diversity and complexity analyses? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though Hillary's corpus is smaller than Trump's by a large margin, her speech readability is \"harder\" by every metric shown above. This goes along the lines of what people have said regarding Trump's speeches being more universally able to be understood than Hillary's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Finally, we're going to conduct sentiment analysis on your corpus. You may use either a dictionary-based analysis or a classifier (or both!). Which approach will you use, and why? (If you're using a dictionary-based approach, comment briefly on which dictionary(ies) may be helpful.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using an already defined NLTK pre-trained sentiment analyzer from https://realpython.com/python-nltk-sentiment-analysis/.\n",
    "\n",
    "I've read it is a bit worse with lengthy texts so I'm not sure if this is the best use for it, but we'll try that out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Generate one hypothesis you can test regarding the sentiment of documents in your corpus. This can be about polarity (positive vs. negative) or something else, as is appropriate for your work and interests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trump speeches are going to be more pessimistic in general than Hillary's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Test your hypothesis with sentiment analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.061, 'neu': 0.767, 'pos': 0.172, 'compound': 1.0}\n",
      "{'neg': 0.109, 'neu': 0.742, 'pos': 0.15, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "print(sia.polarity_scores(clinton))\n",
    "print(sia.polarity_scores(trump))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) How did your hypothesis hold up? Briefly explain your assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Trump and Hillary had close to the same Neutral score, but Trump's positive words are less than Hillary's by this index's measurement, and substantially larger in the negative territory, going along with my hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Did anything you learned about your corpus during your sentiment analysis surprise you? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really surprising, perhaps if you ran this on democrat and republican presidents who have more of a professional role instead of trying to lure people to vote for them the statistics and analysis would've been completely different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summing up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Overall, do you think that these particular analyses were helpful in better understanding your questions and hypotheses about these documents? (It's ok if the answer is no -- not all documents lend themselves to the analyses we've focused on.) Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I feel these types of analyses work amazing for my type of data because there's definitely a lot of nuances in political speeches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) What is the greatest strength of the analysis you conducted in this assignment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely the biggest strenght is finding differences in speech strategies, Trump's speeches were far more effective, perhaps, in appealing to more people than Hillary's.\n",
    "\n",
    "I have no idea if Hillary actually gave 1/4 of the speeches Trump did, but perhaps Trump's massive amounts of speeches combined with a simpler vocabulary and more negative terms to appeal to emotions made the perfect campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) What is the greatest weakness in the analysis you conducted in this assignment? (Remember, your answers can still be brief!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I feel my biggest weakness is having so little Clinton speeches, I couldn't find another database with both candidates' speeches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) What is an additional analysis (or analyses) that you imagine you could do in the future that would help you understand the questions you have about this corpus? The main concept we aren't including in this homework is topic modeling, but you're welcome to comment on anything else that perhaps you've encountered in the wild or simply think up on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could've easily found this out but I'm interested in seeing what each politican had in their platform that the other didn't. For example, hillary probably talked more about the environment and healthcare than Trump, and trump probably talked about taxes and immigration more than Hillary. I guess I'll find this out later.\n",
    "\n",
    "Also, might I add, I had way more fun in this assignment than the last one, perhaps because sentiment analysis is more interesting than finding tokens in a text, but I feel like I could really make some cool personal projects using the analysis I used here!\n",
    "\n",
    "My project is on politician's twitter bios but I was originally doing sport's discussions. I'll see if I can get it done by the end of the semester but if I ever do I'll be sure to show Prof. Jones-Rooy the different analyses and results I made happen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end! \n",
    "\n",
    "Congratulations on finishing your second assignment! Hopefully this was a good chance to practice everything we've gone over in class, as well as to have an opportunity to think about analysing texts in the context of hypotheses. And hopefully it was even fun (and not too tedious!!). \n",
    "\n",
    "If nothing else, you've now already done a lot of the work that's needed for the project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
